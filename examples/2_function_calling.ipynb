{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d3808d",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "InteropRouter supports function calling (tool use) across providers. You define tools using OpenAI's `FunctionToolParam` type, and InteropRouter translates them to each provider's native format.\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- Defining custom tools\n",
    "- Parallel function calling\n",
    "- Built-in web search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b152fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:49.849905Z",
     "iopub.status.busy": "2025-12-23T22:10:49.849798Z",
     "iopub.status.idle": "2025-12-23T22:10:50.487254Z",
     "shell.execute_reply": "2025-12-23T22:10:50.486076Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from anthropic import AsyncAnthropic\n",
    "from google import genai\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from interop_router.router import Router\n",
    "from interop_router.types import ChatMessage, RouterResponse\n",
    "\n",
    "router = Router()\n",
    "router.register(\"openai\", AsyncOpenAI())\n",
    "router.register(\"gemini\", genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\")))\n",
    "router.register(\"anthropic\", AsyncAnthropic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b3d4e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:50.488535Z",
     "iopub.status.busy": "2025-12-23T22:10:50.488306Z",
     "iopub.status.idle": "2025-12-23T22:10:50.493234Z",
     "shell.execute_reply": "2025-12-23T22:10:50.492393Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from openai.types.responses import EasyInputMessageParam\n",
    "from openai.types.responses.response_input_item_param import FunctionCallOutput\n",
    "\n",
    "\n",
    "def extract_text(response: RouterResponse) -> str:\n",
    "    texts: list[str] = []\n",
    "    for chat_message in response.output:\n",
    "        if chat_message.message.get(\"type\") == \"message\":\n",
    "            content = chat_message.message.get(\"content\")\n",
    "            if isinstance(content, list):\n",
    "                for c in content:\n",
    "                    text = c.get(\"text\", \"\")\n",
    "                    if text:\n",
    "                        texts.append(text)\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "\n",
    "def extract_function_calls(response: RouterResponse) -> list[dict]:\n",
    "    calls = []\n",
    "    for chat_message in response.output:\n",
    "        if chat_message.message.get(\"type\") == \"function_call\":\n",
    "            calls.append(\n",
    "                {\n",
    "                    \"call_id\": chat_message.message.get(\"call_id\", \"\"),\n",
    "                    \"name\": chat_message.message.get(\"name\", \"\"),\n",
    "                    \"arguments\": chat_message.message.get(\"arguments\", \"\"),\n",
    "                }\n",
    "            )\n",
    "    return calls\n",
    "\n",
    "\n",
    "def simulate_tool_execution(name: str, arguments: str) -> str:\n",
    "    args = json.loads(arguments)\n",
    "    if name == \"get_weather\":\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"temperature\": 22,\n",
    "                \"unit\": args.get(\"unit\", \"celsius\"),\n",
    "                \"conditions\": \"sunny\",\n",
    "                \"location\": args.get(\"location\", \"Unknown\"),\n",
    "            }\n",
    "        )\n",
    "    elif name == \"get_stock_price\":\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"ticker\": args.get(\"ticker\", \"UNKNOWN\"),\n",
    "                \"price\": 178.50,\n",
    "                \"currency\": \"USD\",\n",
    "            }\n",
    "        )\n",
    "    return json.dumps({\"error\": \"Unknown tool\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4f5a6",
   "metadata": {},
   "source": [
    "## Defining Custom Tools\n",
    "\n",
    "Tools are defined using `FunctionToolParam` from `openai.types.responses.function_tool_param`.\n",
    "\n",
    "See [Function calling with OpenAI](https://platform.openai.com/docs/guides/function-calling), [Function calling with the Gemini API](https://ai.google.dev/gemini-api/docs/function-calling?example=meeting), and [Tool use with Claude](https://platform.claude.com/docs/en/agents-and-tools/tool-use/overview) for provider-specific details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f5a6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:50.494267Z",
     "iopub.status.busy": "2025-12-23T22:10:50.494147Z",
     "iopub.status.idle": "2025-12-23T22:10:50.497241Z",
     "shell.execute_reply": "2025-12-23T22:10:50.496391Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai.types.responses.function_tool_param import FunctionToolParam\n",
    "\n",
    "TOOLS: list[FunctionToolParam] = [\n",
    "    FunctionToolParam(\n",
    "        type=\"function\",\n",
    "        name=\"get_weather\",\n",
    "        description=\"Get the current weather for a given location.\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\": \"The city and country\"},\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "        strict=True,\n",
    "    ),\n",
    "    FunctionToolParam(\n",
    "        type=\"function\",\n",
    "        name=\"get_stock_price\",\n",
    "        description=\"Get the current stock price for a given ticker symbol.\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"ticker\": {\"type\": \"string\", \"description\": \"The stock ticker symbol\"},\n",
    "            },\n",
    "            \"required\": [\"ticker\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "        strict=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c8",
   "metadata": {},
   "source": [
    "## Basic Function Calling\n",
    "\n",
    "The function calling flow:\n",
    "\n",
    "1. Send a request with `tools=` parameter\n",
    "2. Model returns a `function_call` with `call_id`, `name`, and `arguments`\n",
    "3. Execute the function and create a `FunctionCallOutput` with the result\n",
    "4. Send a follow-up request to get the natural language response\n",
    "\n",
    "We demonstrate a full roundtrip: OpenAI handles the function call, Gemini interprets the result, then Anthropic answers a follow-up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b8c9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:50.498247Z",
     "iopub.status.busy": "2025-12-23T22:10:50.498144Z",
     "iopub.status.idle": "2025-12-23T22:10:51.463053Z",
     "shell.execute_reply": "2025-12-23T22:10:51.462051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calls from OpenAI:\n",
      "  get_weather({\"location\":\"Tokyo, Japan\",\"unit\":\"celsius\"})\n"
     ]
    }
   ],
   "source": [
    "messages: list[ChatMessage] = [\n",
    "    ChatMessage(message=EasyInputMessageParam(role=\"user\", content=\"What's the weather in Tokyo? Use celsius.\"))\n",
    "]\n",
    "\n",
    "# Step 1: OpenAI makes the function call\n",
    "response1 = await router.create(input=messages, model=\"gpt-5.2\", tools=TOOLS)\n",
    "\n",
    "function_calls = extract_function_calls(response1)\n",
    "print(\"Function calls from OpenAI:\")\n",
    "for call in function_calls:\n",
    "    print(f\"  {call['name']}({call['arguments']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c9d0e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:51.464282Z",
     "iopub.status.busy": "2025-12-23T22:10:51.464170Z",
     "iopub.status.idle": "2025-12-23T22:10:51.467469Z",
     "shell.execute_reply": "2025-12-23T22:10:51.466556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool result: {\"temperature\": 22, \"unit\": \"celsius\", \"conditions\": \"sunny\", \"location\": \"Tokyo, Japan\"}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Add the function call and its output to the conversation\n",
    "messages.extend(response1.output)\n",
    "\n",
    "for call in function_calls:\n",
    "    result = simulate_tool_execution(call[\"name\"], call[\"arguments\"])\n",
    "    messages.append(\n",
    "        ChatMessage(\n",
    "            message=FunctionCallOutput(\n",
    "                call_id=call[\"call_id\"],\n",
    "                output=result,\n",
    "                type=\"function_call_output\",\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print(f\"Tool result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d0e1f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:51.468539Z",
     "iopub.status.busy": "2025-12-23T22:10:51.468436Z",
     "iopub.status.idle": "2025-12-23T22:10:52.219061Z",
     "shell.execute_reply": "2025-12-23T22:10:52.218132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini response:\n",
      "The current weather in Tokyo is sunny with a temperature of 22°C.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Gemini interprets the result\n",
    "response2 = await router.create(input=messages, model=\"gemini-3-flash-preview\")\n",
    "messages.extend(response2.output)\n",
    "\n",
    "print(\"Gemini response:\")\n",
    "print(extract_text(response2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e1f2a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:52.220266Z",
     "iopub.status.busy": "2025-12-23T22:10:52.220154Z",
     "iopub.status.idle": "2025-12-23T22:10:55.549489Z",
     "shell.execute_reply": "2025-12-23T22:10:55.548473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic response:\n",
      "For 22°C and sunny weather in Tokyo, here are some clothing recommendations:\n",
      "\n",
      "**Light layers are ideal:**\n",
      "- **Top**: A light long-sleeve shirt, t-shirt, or short-sleeve top\n",
      "- **Outerwear**: A light cardigan, denim jacket, or thin sweater (useful if it gets cooler in the evening)\n",
      "- **Bottoms**: Lightweight pants, jeans, or shorts\n",
      "- **Footwear**: Comfortable sneakers, casual shoes, or loafers\n",
      "\n",
      "**Additional items to consider:**\n",
      "- **Sunglasses and a hat** - protection from the sun\n",
      "- **Sunscreen** - important since it's sunny\n",
      "- **Light scarf** - optional, but nice for layering\n",
      "- **Small bag or backpack** - to carry essentials\n",
      "\n",
      "**General tips:**\n",
      "- 22°C is mild and pleasant, so you don't need heavy winter clothing\n",
      "- Since the sun is out, you'll likely feel warmer in direct sunlight\n",
      "- It might be slightly cooler in the evening or in shaded areas, so layering is smart\n",
      "- Comfortable walking shoes are great if you plan to explore the city\n",
      "\n",
      "You'll be comfortable in casual, breathable clothing!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Continue the conversation with Anthropic\n",
    "messages.append(ChatMessage(message=EasyInputMessageParam(role=\"user\", content=\"What should I wear for that weather?\")))\n",
    "\n",
    "response3 = await router.create(\n",
    "    input=messages,\n",
    "    model=\"claude-haiku-4-5-20251001\",\n",
    "    max_output_tokens=16_000,\n",
    ")\n",
    "messages.extend(response3.output)\n",
    "\n",
    "print(\"Anthropic response:\")\n",
    "print(extract_text(response3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## Parallel Function Calling\n",
    "\n",
    "Models can call multiple tools in a single response, which requires special handling of reasoning depending on the provider which we handle transparently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a3b4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:55.550877Z",
     "iopub.status.busy": "2025-12-23T22:10:55.550758Z",
     "iopub.status.idle": "2025-12-23T22:10:57.364761Z",
     "shell.execute_reply": "2025-12-23T22:10:57.363822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI made 2 parallel function calls:\n",
      "  get_weather({\"location\":\"New York City, US\",\"unit\":\"fahrenheit\"})\n",
      "  get_stock_price({\"ticker\":\"AAPL\"})\n"
     ]
    }
   ],
   "source": [
    "messages_parallel: list[ChatMessage] = [\n",
    "    ChatMessage(\n",
    "        message=EasyInputMessageParam(\n",
    "            role=\"user\",\n",
    "            content=\"I need the weather in NYC (fahrenheit) and Apple's stock price. Call both tools.\",\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "response_parallel = await router.create(\n",
    "    input=messages_parallel,\n",
    "    model=\"gpt-5.2\",\n",
    "    tools=TOOLS,\n",
    "    tool_choice=\"required\",\n",
    "    instructions=\"You are a helpful assistant who calls tools.\",\n",
    ")\n",
    "\n",
    "parallel_calls = extract_function_calls(response_parallel)\n",
    "print(f\"OpenAI made {len(parallel_calls)} parallel function calls:\")\n",
    "for call in parallel_calls:\n",
    "    print(f\"  {call['name']}({call['arguments']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b4c5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:57.365997Z",
     "iopub.status.busy": "2025-12-23T22:10:57.365869Z",
     "iopub.status.idle": "2025-12-23T22:10:57.369093Z",
     "shell.execute_reply": "2025-12-23T22:10:57.368353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather result: {\"temperature\": 22, \"unit\": \"fahrenheit\", \"conditions\": \"sunny\", \"location\": \"New York City, US\"}\n",
      "get_stock_price result: {\"ticker\": \"AAPL\", \"price\": 178.5, \"currency\": \"USD\"}\n"
     ]
    }
   ],
   "source": [
    "# Provide results for all parallel calls\n",
    "messages_parallel.extend(response_parallel.output)\n",
    "\n",
    "for call in parallel_calls:\n",
    "    result = simulate_tool_execution(call[\"name\"], call[\"arguments\"])\n",
    "    messages_parallel.append(\n",
    "        ChatMessage(\n",
    "            message=FunctionCallOutput(\n",
    "                call_id=call[\"call_id\"],\n",
    "                output=result,\n",
    "                type=\"function_call_output\",\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print(f\"{call['name']} result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c5d6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:57.370320Z",
     "iopub.status.busy": "2025-12-23T22:10:57.370220Z",
     "iopub.status.idle": "2025-12-23T22:10:58.677334Z",
     "shell.execute_reply": "2025-12-23T22:10:58.676221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini response:\n",
      "The current weather in New York City is 22°F and sunny. Apple's stock price is $178.50.\n"
     ]
    }
   ],
   "source": [
    "# Gemini interprets both results\n",
    "response_parallel_2 = await router.create(input=messages_parallel, model=\"gemini-3-flash-preview\")\n",
    "messages_parallel.extend(response_parallel_2.output)\n",
    "\n",
    "print(\"Gemini response:\")\n",
    "print(extract_text(response_parallel_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d6e7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:10:58.678553Z",
     "iopub.status.busy": "2025-12-23T22:10:58.678415Z",
     "iopub.status.idle": "2025-12-23T22:11:01.388156Z",
     "shell.execute_reply": "2025-12-23T22:11:01.387284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic response:\n",
      "The weather and stock prices are independent of each other, so the sunny 22°F conditions in NYC shouldn't influence your investment decision for Apple stock.\n",
      "\n",
      "When deciding whether to buy AAPL at $178.50, consider factors like:\n",
      "\n",
      "- **Apple's fundamentals** - earnings, revenue growth, profit margins, competitive position\n",
      "- **Market conditions** - overall market trends, interest rates, economic outlook\n",
      "- **Your personal situation** - investment goals, time horizon, risk tolerance, portfolio diversification\n",
      "- **Valuation** - is $178.50 a fair price relative to earnings and growth prospects?\n",
      "- **Technical analysis** - if you use that approach, support/resistance levels, trends\n",
      "\n",
      "I'd recommend researching Apple's latest earnings reports, analyst ratings, and your own investment strategy rather than weather conditions. If you're looking for stock advice, consider consulting a financial advisor who can assess your specific situation.\n"
     ]
    }
   ],
   "source": [
    "# Continue with Anthropic\n",
    "messages_parallel.append(\n",
    "    ChatMessage(message=EasyInputMessageParam(role=\"user\", content=\"Should I buy AAPL stock today given the weather?\"))\n",
    ")\n",
    "\n",
    "response_parallel_3 = await router.create(\n",
    "    input=messages_parallel,\n",
    "    model=\"claude-haiku-4-5-20251001\",\n",
    "    max_output_tokens=16_000,\n",
    ")\n",
    "messages_parallel.extend(response_parallel_3.output)\n",
    "\n",
    "print(\"Anthropic response:\")\n",
    "print(extract_text(response_parallel_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## Built-in Web Search\n",
    "\n",
    "InteropRouter supports built-in web search via `WebSearchToolParam`. OpenAI, Gemini, and Anthropic all have native web search capabilities that InteropRouter maps to a unified interface.\n",
    "\n",
    "Use `include=[\"web_search_call.results\", \"web_search_call.action.sources\"]` to get search metadata in the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f8a9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:11:01.389297Z",
     "iopub.status.busy": "2025-12-23T22:11:01.389187Z",
     "iopub.status.idle": "2025-12-23T22:11:09.819515Z",
     "shell.execute_reply": "2025-12-23T22:11:09.818465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini web search response:\n",
      "A very recent and significant article (dated December 22, 2025) discusses a breakthrough from researchers at **Duke University** who have developed a new AI framework that can find simple, readable rules within extremely complex systems.\n",
      "\n",
      "### Key Highlights of the Article:\n",
      "*   **The Problem:** Scientists often struggle to find mathematical equations for systems with thousands of interacting variables, such as weather patterns, climate change, or complex biological signals.\n",
      "*   **The AI's Capability:** Inspired by \"dynamicists\" like Isaac Newton, this AI analyzes data from evolving systems and reduces massive complexity into compact, understandable equations. It can take a system with hundreds of variables and distill it down to its core governing rules.\n",
      "*   **Applications:** The method is being applied across physics, engineering, and biology. Researchers believe it will help \"see through the chaos\" of data to uncover fundamental laws of nature that were previously too difficult for humans or traditional computers to articulate.\n",
      "*   **Significance:** This marks a shift from \"black box\" AI (where we don't know how the AI reaches a conclusion) to **interpretable AI**, where the machine actually helps humans understand the underlying science.\n",
      "\n",
      "This development is being hailed as a major tool for scientific discovery, potentially accelerating our understanding of everything from electrical circuits to global climate trends.\n"
     ]
    }
   ],
   "source": [
    "from openai.types.responses import WebSearchToolParam\n",
    "\n",
    "# Continues the conversation from above\n",
    "messages_parallel.append(\n",
    "    ChatMessage(message=EasyInputMessageParam(role=\"user\", content=\"Now can you look up one latest article about AI?\"))\n",
    ")\n",
    "\n",
    "# Gemini performs web search\n",
    "response_search = await router.create(\n",
    "    input=messages_parallel,\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    tools=[WebSearchToolParam(type=\"web_search\")],\n",
    "    include=[\"web_search_call.results\", \"web_search_call.action.sources\"],\n",
    ")\n",
    "messages_parallel.extend(response_search.output)\n",
    "\n",
    "print(\"Gemini web search response:\")\n",
    "print(extract_text(response_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8a9b0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:11:09.820696Z",
     "iopub.status.busy": "2025-12-23T22:11:09.820587Z",
     "iopub.status.idle": "2025-12-23T22:11:11.814060Z",
     "shell.execute_reply": "2025-12-23T22:11:11.813065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic summary:\n",
      "Duke University researchers have developed an AI framework that can distill complex systems with thousands of variables into simple, readable mathematical equations, enabling better scientific understanding across physics, engineering, and biology.\n"
     ]
    }
   ],
   "source": [
    "# Anthropic summarizes\n",
    "messages_parallel.append(\n",
    "    ChatMessage(message=EasyInputMessageParam(role=\"user\", content=\"Can you summarize that article in one sentence?\"))\n",
    ")\n",
    "\n",
    "response_search_2 = await router.create(\n",
    "    input=messages_parallel,\n",
    "    model=\"claude-haiku-4-5-20251001\",\n",
    "    max_output_tokens=16_000,\n",
    ")\n",
    "messages_parallel.extend(response_search_2.output)\n",
    "\n",
    "print(\"Anthropic summary:\")\n",
    "print(extract_text(response_search_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b0c1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T22:11:11.815175Z",
     "iopub.status.busy": "2025-12-23T22:11:11.815066Z",
     "iopub.status.idle": "2025-12-23T22:11:23.932175Z",
     "shell.execute_reply": "2025-12-23T22:11:23.931257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini follow-up:\n",
      "Beyond the breakthrough in **interpretable AI** (like the Duke University framework you mentioned), several other major themes are dominating the AI landscape this December 2025:\n",
      "\n",
      "### 1. The \"Agentic\" Shift\n",
      "The biggest trend right now is the transition from AI as a \"chatbot\" to AI as an **agent**. \n",
      "*   **Autonomous Actions:** New systems like **OpenAI’s \"Operator\"** and **Anthropic’s Claude 4.5** are being used to navigate web browsers, schedule appointments, and execute complex workflows independently.\n",
      "*   **Enterprise Integration:** Companies are launching \"agentic layers\" (like Salesforce’s Agentforce) that allow businesses to deploy autonomous agents to handle customer service, logistics, and marketing without human intervention.\n",
      "\n",
      "### 2. \"Vibe Coding\" & MCP\n",
      "In the developer world, the focus has shifted toward making AI infrastructure more standardized and accessible:\n",
      "*   **Vibe Coding:** This is a trending term for programming using purely natural language. New tools allow people with zero technical background to build functional apps just by describing their \"vibe\" or intent.\n",
      "*   **Model Context Protocol (MCP):** A new standard that is becoming as common as the web server. It allows AI models to securely and easily \"plug into\" your local data (like Google Drive, Slack, or GitHub) to provide much more relevant and personalized help.\n",
      "\n",
      "### 3. AI Regulation & the \"Bill of Rights\"\n",
      "As AI becomes more integrated, legal and ethical debates are heating up:\n",
      "*   **State vs. Federal Battles:** In the U.S., states like Florida are pushing for an **AI Bill of Rights** to protect individuals' likenesses and prohibit AI from providing mental health counseling. This is creating a \"collision course\" with federal efforts to standardize regulation.\n",
      "*   **Data Scraping Lawsuits:** Major legal battles are intensifying between platforms like Reddit and AI giants (OpenAI, Google) over the use of user data for training models.\n",
      "\n",
      "### 4. Hardware & \"Compute Giants\"\n",
      "The physical side of AI is seeing massive financial moves:\n",
      "*   **Nvidia’s Mega-Investment:** Nvidia is reportedly moving toward a $100 billion strategic tie-up with OpenAI to scale up the next generation of AI data centers.\n",
      "*   **Sustainable Infrastructure:** There is a heavy focus on \"water-less\" cooling systems and carbon-free energy for data centers as the environmental footprint of AI comes under intense public scrutiny.\n",
      "\n",
      "### 5. Multimodal Creativity\n",
      "AI isn't just generating text anymore; it's mastering **video and physics**:\n",
      "*   **Video Generation:** Tools like **Google Veo 3** have reached a level where they can maintain consistent \"video tracking\"—meaning characters and objects stay perfectly consistent across long, cinematic shots, making AI-generated film a real possibility for 2026.\n"
     ]
    }
   ],
   "source": [
    "# Back to Gemini for follow-up\n",
    "messages_parallel.append(\n",
    "    ChatMessage(message=EasyInputMessageParam(role=\"user\", content=\"Thank you! What other topics are trending in AI?\"))\n",
    ")\n",
    "\n",
    "response_search_3 = await router.create(\n",
    "    input=messages_parallel,\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    tools=[WebSearchToolParam(type=\"web_search\")],\n",
    "    include=[\"web_search_call.results\", \"web_search_call.action.sources\"],\n",
    ")\n",
    "messages_parallel.extend(response_search_3.output)\n",
    "\n",
    "print(\"Gemini follow-up:\")\n",
    "print(extract_text(response_search_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interop-router",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
